{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import functools\n",
    "import math\n",
    "import collections\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import ipdb\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd \n",
    "import grid2op \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Projects imports\n",
    "\n",
    "import auxiliary.util as util\n",
    "import auxiliary.config as config\n",
    "import auxiliary.grid2op_util as g2o_util\n",
    "from auxiliary.generate_action_space import action_identificator\n",
    "import data_preprocessing_analysis.imitation_data_preprocessing as idp\n",
    "\n",
    "# Set working directory\n",
    "util.set_wd_to_package_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = config['paths']['processed_tutor_imitation']\n",
    "con_matrix_path = config['paths']['con_matrix_cache']\n",
    "fstats_path = config['paths']['feature_statistics']\n",
    "\n",
    "chronics_excluded = [310, 446, 777]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processed Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block defines several data aggregates, such as counters. The processed data is loaded a file at a time, gradually filling the data aggregates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sub = 14\n",
    "\n",
    "#Inbstantiate the counter objects\n",
    "counters = {\n",
    "    'n_datapoints':0,\n",
    "    'n_days_completed':0,\n",
    "    'n_chronics':0,\n",
    "    'set_hash': collections.Counter(),\n",
    "    'res_hash': collections.Counter(),\n",
    "    'tv_hash': collections.Counter(),\n",
    "    'sub_changed': (n_sub+1) * [0],\n",
    "    'changed_subs_n': n_sub * [0],\n",
    "    'sub_info': []\n",
    "}\n",
    "        \n",
    "# To count numpy arrays, we index their counters with hashes, stored in hash dictionaries:\n",
    "hash_to_act = {} #'Set'-action hashes\n",
    "hash_to_tv = {} #Topology vector hashes\n",
    "hash_to_res = {} #Resulting (i.e. post-action) topology vector hashes\n",
    "\n",
    "\n",
    "for f in tqdm(list(Path(processed_data_path).rglob('*.json'))):\n",
    "    with open(f, 'r') as file:\n",
    "            dps = json.loads(file.read())\n",
    "    \n",
    "    counters['n_chronics']+=1\n",
    "    counters['n_days_completed']+=dps[0]['dayscomp']\n",
    "    for dp in dps:\n",
    "        #Increase n. datapoints\n",
    "        counters['n_datapoints']+=1\n",
    "        \n",
    "        #Count set_topo_vect\n",
    "        hsh_set = util.hash_nparray(np.array(dp['set_topo_vect']))\n",
    "        if hsh_set not in hash_to_act:\n",
    "            hash_to_act[hsh_set] = dp['set_topo_vect']\n",
    "        counters['set_hash'][hsh_set]+=1\n",
    "        \n",
    "        #Count res_topo_vect\n",
    "        hsh_res = util.hash_nparray(np.array(dp['res_topo_vect']))\n",
    "        if hsh_res not in hash_to_res:\n",
    "            hash_to_res[hsh_res] = dp['res_topo_vect']\n",
    "        counters['res_hash'][hsh_res]+=1\n",
    "        \n",
    "        #Count topo_vect\n",
    "        hsh_tv = util.hash_nparray(np.array(dp['topo_vect']))\n",
    "        if hsh_tv not in hash_to_tv:\n",
    "            hash_to_tv[hsh_tv] = dp['topo_vect']\n",
    "        counters['tv_hash'][hsh_tv]+=1\n",
    "        \n",
    "        #Count substations affected\n",
    "        action_per_sub = g2o_util.tv_groupby_subst(dp['set_topo_vect'],dp['sub_info'])\n",
    "        try:\n",
    "            changed_subs_id = [np.any(a) for i,a in enumerate(action_per_sub)].index(True)\n",
    "            counters['sub_changed'][changed_subs_id] += 1\n",
    "        except:\n",
    "            counters['sub_changed'][-1] += 1\n",
    "\n",
    "        #Count topological depth of resulting topologies\n",
    "        #ASSUMPTION: reference topology is the topology where all objects are connected to bus 1\n",
    "        res_per_sub = g2o_util.tv_groupby_subst(dp['res_topo_vect'],dp['sub_info'])\n",
    "        changed_subs_n = sum([2 in res for i,res in enumerate(res_per_sub)])\n",
    "        counters['changed_subs_n'][changed_subs_n] += 1\n",
    "        \n",
    "        #Set sub info\n",
    "        counters['sub_info'] = dp['sub_info']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of chronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Chronics: {counters['n_chronics']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Days completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Days completed: {counters['n_days_completed']}\")\n",
    "print(f\"Fraction days completed: {counters['n_days_completed']/(28*counters['n_chronics'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of actions/datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the term 'action' here instead of 'datapoint'\n",
    "print(f\"Actions: {counters['n_datapoints']}\")\n",
    "print(f\"Mean actions per day: {counters['n_datapoints']/(28*counters['n_chronics'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Action statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Distinct actions: {len(counters['set_hash'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_nothing_hash = [h for h,t in hash_to_act.items() if sum(t)==0][0]\n",
    "print(f\"Do-nothing actions: {counters['set_hash'][do_nothing_hash]}\")\n",
    "print(f\"Fraction do-nothing actions: {counters['set_hash'][do_nothing_hash]/counters['n_datapoints']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Action entropy: {entropy(list(counters['set_hash'].values()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Action distribution plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the actions into the representation:\n",
    "\n",
    "(affected substation index, 'set' configuration of objects at this substation)\n",
    "\n",
    "do-nothing actions are simply transformed into '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting actions into format so that actions at substations\n",
    "standard_sub_info = [3, 6, 4, 6, 5, 6, 3, 2, 5, 3, 3, 3, 4, 3]\n",
    "do_nothing_hash = [h for h,t in hash_to_act.items() if sum(t)==0][0]\n",
    "\n",
    "transformed_act_counter = collections.Counter()\n",
    "\n",
    "# Filling in the counter for the transformed actions\n",
    "for h,c in counters['set_hash'].items():\n",
    "    a = hash_to_act[h]\n",
    "    a_per_substation = g2o_util.tv_groupby_subst(a,standard_sub_info)\n",
    "    \n",
    "    if h == do_nothing_hash:\n",
    "        transformed_act_counter[-1] += c\n",
    "    else:\n",
    "        changed_sub_id = [np.any(a) for a in a_per_substation].index(True)\n",
    "        action = (changed_sub_id,tuple(a_per_substation[changed_sub_id]))\n",
    "        transformed_act_counter[action] += c\n",
    "        \n",
    "#Gettings the keys of this counter\n",
    "keys = list(transformed_act_counter.keys())\n",
    "keys = sorted([t for t in keys if type(t)==tuple])\n",
    "keys = [-1] + keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = {\n",
    "    -1:'k',\n",
    "    1:'b',\n",
    "    2:'g',\n",
    "    3:'r',\n",
    "    4:'c',\n",
    "    5:'m',\n",
    "    8:'y',\n",
    "    12:'olive',\n",
    "}\n",
    "\n",
    "weight = [transformed_act_counter[i] for i in keys]\n",
    "_, _, patches = plt.hist(range(len(weight)),weights=weight,bins=range(len(weight)+1))\n",
    "\n",
    "\n",
    "#Applying colors\n",
    "labels_set = []\n",
    "for j,t in enumerate(keys[:-1]):\n",
    "    if type(t) == int:\n",
    "        continue\n",
    "    patches[j].set_facecolor(colormap[t[0]])\n",
    "    if t[0] not in labels_set:\n",
    "        patches[j].set_label(t[0])\n",
    "        labels_set.append(t[0])\n",
    "patches[0].set_facecolor(colormap[-1])\n",
    "patches[0].set_label(\"No Action\")\n",
    "\n",
    "plt.xlabel('Action index')\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.gca().legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [c for _,c in transformed_act_counter.most_common()]\n",
    "_, _, patches = plt.hist(range(len(weight)), weights=weight,bins=range(len(weight)+1))\n",
    "\n",
    "#Applying colors\n",
    "labels_set = []\n",
    "for i,(v,_) in enumerate(transformed_act_counter.most_common()):\n",
    "    if type(v) == int:\n",
    "        patches[i].set_facecolor(colormap[-1])\n",
    "        patches[i].set_label(\"No Action\")\n",
    "        continue\n",
    "    patches[i].set_facecolor(colormap[v[0]])\n",
    "    if v[0] not in labels_set:\n",
    "        patches[i].set_label(v[0])\n",
    "        labels_set.append(v[0])\n",
    "\n",
    "\n",
    "#_ = [patches[i].set_facecolor(colormap[v if v==-1 else v[0]])\n",
    "# for i,(v,_) in enumerate(transformed_act_counter.most_common())]\n",
    "\n",
    "plt.gca().legend()\n",
    "plt.xlabel('Action index ordered by frequency')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting TV Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_counter = counters['tv_hash']\n",
    "val, weight = zip(*[(i, v) for i,(k,v) in enumerate(tv_counter.most_common())])\n",
    "plt.hist(val[0:100], weights=weight[0:100],bins=val[0:101])\n",
    "\n",
    "patches[0].set_facecolor(colormap[-1])\n",
    "plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "plt.xlabel(\"Pre-Action Topology by Frequency\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resulting TV Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_counter = counters['res_hash']\n",
    "val, weight = zip(*[(i, v) for i,(k,v) in enumerate(res_counter.most_common())])\n",
    "plt.hist(val[0:100], weights=weight[0:100],bins=val[0:101])\n",
    "\n",
    "patches[0].set_facecolor(colormap[-1])\n",
    "plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,0))\n",
    "plt.xlabel(\"Resulting Topology by Frequency\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substations acted on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substations_with_actions = [-1,1,2,3,4,5,8,12]\n",
    "colormap = {\n",
    "    -1:'k',\n",
    "    1:'b',\n",
    "    2:'g',\n",
    "    3:'r',\n",
    "    4:'c',\n",
    "    5:'m',\n",
    "    8:'y',\n",
    "    12:'k',\n",
    "}\n",
    "\n",
    "patches = plt.bar(['No Action'] + [str(b) for b in substations_with_actions][1:],\n",
    "                np.array(counters['sub_changed'])[substations_with_actions])\n",
    "_ = [p.set_facecolor(c) for p,c in zip(patches,colormap.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topological Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_nothing_hash = [h for h,t in hash_to_act.items() if sum(t)==0][0]\n",
    "\n",
    "def mean_index(lst):\n",
    "    return np.sum(np.array([i*v for i,v in enumerate(lst)]))/sum(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_nonzero = np.count_nonzero(counters['changed_subs_n'])\n",
    "\n",
    "plt.bar([str(n) for n in range(n_sub)][0:nr_nonzero],list(counters['changed_subs_n'])[0:nr_nonzero])\n",
    "plt.title('')\n",
    "\n",
    "plt.xlabel(\"Topological Depth\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
