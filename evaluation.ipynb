{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f6a0104-218a-4561-bf79-13a2c7847039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Project imports\n",
    "from auxiliary.config import get_config, ModelType, NetworkType\n",
    "from training.models import GCN, FCNN\n",
    "from training.dataloader import DataLoader\n",
    "from training.training import Run, evaluate_dataset, process_datapoint\n",
    "import training.evaluation as metrics\n",
    "from training.postprocessing import ActSpaceCache\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb5ac958-2287-4b00-a502-ff0489499e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "train_config = config['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c32f12c6805894",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'settings': {'train_log_freq': 2000,\n",
       "  'val_log_freq': 50000,\n",
       "  'dp_per_val_log': 20000,\n",
       "  'advanced_val_analysis': True,\n",
       "  'line_outages_considered': [-1, 0, 1, 2, 3, 4, 5, 6, 12]},\n",
       " 'hyperparams': {'model_type': <ModelType.FCNN: 'FCNN'>,\n",
       "  'n_epoch': 100,\n",
       "  'lr': 0.0005,\n",
       "  'N_node_hidden': 230,\n",
       "  'LReLu_neg_slope': 0.1,\n",
       "  'batch_size': 64,\n",
       "  'label_smoothing_alpha': 0,\n",
       "  'weight_init_std': 3,\n",
       "  'weight_decay': 0,\n",
       "  'early_stopping_patience': 50,\n",
       "  'label_weights': {'type': <LabelWeightsType.Y_AND_P: 'Y_AND_P'>,\n",
       "   'non_masked_weight': 0.1}},\n",
       " 'constants': {'estimated_train_size': 36497},\n",
       " 'GCN': {'hyperparams': {'network_type': <NetworkType.HETERO: 'heterogeneous'>,\n",
       "   'N_GCN_layers': 8,\n",
       "   'aggr': <AggrType.ADD: 'add'>,\n",
       "   'layer_type': <LayerType.SAGECONV: 'SAGEConv'>,\n",
       "   'GINConv_nn_depth': 2},\n",
       "  'constants': {'N_f_gen': 3, 'N_f_load': 3, 'N_f_endpoint': 6}},\n",
       " 'FCNN': {'hyperparams': {'N_layers': 5},\n",
       "  'constants': {'size_in': 344, 'size_out': 56}},\n",
       " 'wandb': {'model_name': 'test',\n",
       "  'model_tags': ['test'],\n",
       "  'group': None,\n",
       "  'project': 'imitation_learning_power',\n",
       "  'entity': 'mattholomew',\n",
       "  'mode': 'online'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d369f-4d93-4085-8114-25e6355c16b2",
   "metadata": {},
   "source": [
    "# Analyzing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12279754e6314436",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Loading model\n",
    "Note: config must contain the hyperparameters used by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66d76ce5-e450-49f2-9dd3-feb2cfb5b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = config['training']['hyperparams']['model_type']\n",
    "\n",
    "if model_type == ModelType.FCNN:\n",
    "    model = FCNN(train_config['hyperparams']['LReLu_neg_slope'],\n",
    "                 train_config['hyperparams']['weight_init_std'],\n",
    "                 train_config['FCNN']['constants']['size_in'],\n",
    "                 train_config['FCNN']['constants']['size_out'],\n",
    "                 train_config['FCNN']['hyperparams']['N_layers'],\n",
    "                 train_config['hyperparams']['N_node_hidden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc8d82b6db1c26f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = config['paths']['model']\n",
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79855ff4-99e8-4275-b15a-adaf482d15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_processed_data_path = config['paths']['data']['processed']\n",
    "seen_matrix_cache_path = seen_processed_data_path + 'auxiliary_data_objects/con_matrix_cache.json'\n",
    "\n",
    "unseen_processed_data_path = 'data/processed/greedy_unseen/'\n",
    "unseen_matrix_cache_path = unseen_processed_data_path + 'auxiliary_data_objects/con_matrix_cache.json'\n",
    "\n",
    "feature_statistics_path = seen_processed_data_path + 'auxiliary_data_objects/feature_stats.json'\n",
    "model_type = config['training']['hyperparams']['model_type']\n",
    "network_type = train_config['GCN']['hyperparams']['network_type']\n",
    "\n",
    "dataloaders = {'seen': {}, 'unseen': {}}\n",
    "for data, processed_data_path, matrix_cache_path in [('seen', seen_processed_data_path, seen_matrix_cache_path)]:#: , #('unseen', unseen_processed_data_path, unseen_matrix_cache_path)):\n",
    "    for partition in ('train', 'val', 'test'):\n",
    "        dataloaders[data][partition] = DataLoader(processed_data_path + '/' + partition, matrix_cache_path, feature_statistics_path, 'cpu',  model_type, network_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16b2468179dcf853",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "init_env() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 21\u001B[0m\n\u001B[1;32m     18\u001B[0m eval_metrics \u001B[38;5;241m=\u001B[39m IAM(val_metrics_dict)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Initialize action space cache used for\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m as_cache \u001B[38;5;241m=\u001B[39m \u001B[43mActSpaceCache\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline_outages_considered\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_config\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msettings\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mline_outages_considered\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/MSc_Thesis/GNN_PN_Imitation_Learning/training/postprocessing.py:44\u001B[0m, in \u001B[0;36mActSpaceCache.__init__\u001B[0;34m(self, env, line_outages_considered, reduce)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;124;03m----------\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03m    -1 in this list represent no line removed. The default is [-1].\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m env \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 44\u001B[0m     env \u001B[38;5;241m=\u001B[39m \u001B[43mg2o_util\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit_env\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrid2op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mRules\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAlwaysLegal\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_act_space_per_lo \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m lo \u001B[38;5;129;01min\u001B[39;00m line_outages_considered:\n",
      "\u001B[0;31mTypeError\u001B[0m: init_env() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "# Initialize metrics objects\n",
    "IA = metrics.IncrementalAverage\n",
    "metrics_dict = {\n",
    "    'macro_accuracy': (metrics.macro_accuracy, IA()),\n",
    "    'micro_accuracy': (metrics.micro_accuracy, IA()),\n",
    "    'n_predicted_changes': (metrics.n_predicted_changes, IA()),\n",
    "    'any_predicted_changes': (metrics.any_predicted_changes, IA()),\n",
    "    'macro_accuracy_one_sub': (metrics.macro_accuracy_one_sub, IA()),\n",
    "    'micro_accuracy_one_sub': (metrics.micro_accuracy_one_sub, IA()),\n",
    "    'train_loss': (lambda **kwargs: kwargs['l'], IA()),\n",
    "    'accuracy_predicted_substation':\n",
    "        (metrics.accuracy_predicted_substation, IA())\n",
    "}\n",
    "val_metrics_dict = dict([('val_' + k, v) for k, v in metrics_dict.items()])\n",
    "val_metrics_dict['val_macro_accuracy_valid'] = (metrics.macro_accuracy_valid, IA())\n",
    "val_metrics_dict['val_micro_accuracy_valid'] = (metrics.micro_accuracy_valid, IA())\n",
    "IAM = metrics.IncrementalAverageMetrics\n",
    "eval_metrics = IAM(val_metrics_dict)\n",
    "\n",
    "# Initialize action space cache used for\n",
    "as_cache = ActSpaceCache(line_outages_considered=train_config['settings']['line_outages_considered'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5133f046e2fa674",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Evaluating seen topologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d37910a-9e0d-4f30-bfd9-23e982113c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%tb\n",
    "plt.ioff()\n",
    "results = {}\n",
    "\n",
    "for partition, dataloader in dataloaders['seen'].items():\n",
    "        \n",
    "    eval_metrics.reset()\n",
    "    _ = evaluate_dataset(model, dataloader, as_cache, eval_metrics)\n",
    "\n",
    "    results[partition] = {\n",
    "        'val_macro_accuracy_valid':  eval_metrics.metrics_dict['val_macro_accuracy_valid'][1].get(),\n",
    "        'loss':  eval_metrics.metrics_dict['val_train_loss'][1].get()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d6f42f8b089f5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Evaluating unseen topologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34c19101594080",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "for data, processed_data_path, matrix_cache_path in [('unseen', unseen_processed_data_path, unseen_matrix_cache_path)]:\n",
    "    for partition in ('train', 'val', 'test'):\n",
    "        dataloaders[data][partition] = DataLoader(processed_data_path + '/' + partition, matrix_cache_path, feature_statistics_path, 'cpu',  model_type, network_type)\n",
    "\n",
    "# Initialize metrics objects\n",
    "IA = metrics.IncrementalAverage\n",
    "metrics_dict = {\n",
    "    'macro_accuracy': (metrics.macro_accuracy, IA()),\n",
    "    'micro_accuracy': (metrics.micro_accuracy, IA()),\n",
    "    'n_predicted_changes': (metrics.n_predicted_changes, IA()),\n",
    "    'any_predicted_changes': (metrics.any_predicted_changes, IA()),\n",
    "    'macro_accuracy_one_sub': (metrics.macro_accuracy_one_sub, IA()),\n",
    "    'micro_accuracy_one_sub': (metrics.micro_accuracy_one_sub, IA()),\n",
    "    'train_loss': (lambda **kwargs: kwargs['l'], IA()),\n",
    "    'accuracy_predicted_substation':\n",
    "        (metrics.accuracy_predicted_substation, IA())\n",
    "}\n",
    "val_metrics_dict = dict([('val_' + k, v) for k, v in metrics_dict.items()])\n",
    "val_metrics_dict['val_macro_accuracy_valid'] = (metrics.macro_accuracy_valid, IA())\n",
    "val_metrics_dict['val_micro_accuracy_valid'] = (metrics.micro_accuracy_valid, IA())\n",
    "IAM = metrics.IncrementalAverageMetrics\n",
    "eval_metrics = IAM(val_metrics_dict)\n",
    "\n",
    "# Initialize action space cache used for\n",
    "as_cache = ActSpaceCache(line_outages_considered=train_config['settings']['line_outages_considered'])\n",
    "#_ = evaluate_dataset(model, dataloader, as_cache, eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46bb3715fea10f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%tb\n",
    "plt.ioff()\n",
    "results = {}\n",
    "\n",
    "for partition, dataloader in dataloaders['unseen'].items():\n",
    "        \n",
    "    eval_metrics.reset()\n",
    "    figures = evaluate_dataset(model, dataloader, as_cache, eval_metrics)\n",
    "\n",
    "    results[partition] = {\n",
    "        'val_macro_accuracy_valid':  eval_metrics.metrics_dict['val_macro_accuracy_valid'][1].get(),\n",
    "        'loss':  eval_metrics.metrics_dict['val_train_loss'][1].get()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286a3f9d94553011",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluating multiple models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192b8b1-2bf3-46c0-8e8a-6d2a8b58c238",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Seen Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c8946c12d37d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "model_numbers = np.arange(1,6)\n",
    "results = {}\n",
    "\n",
    "# Data\n",
    "seen_processed_data_path = config['paths']['data']['processed']\n",
    "seen_matrix_cache_path = seen_processed_data_path + 'auxiliary_data_objects/con_matrix_cache.json'\n",
    "feature_statistics_path = seen_processed_data_path + 'auxiliary_data_objects/feature_stats.json'\n",
    "model_type = config['training']['hyperparams']['model_type']\n",
    "\n",
    "# Metrics\n",
    "# Initialize metrics objects\n",
    "IA = metrics.IncrementalAverage\n",
    "metrics_dict = {\n",
    "    'macro_accuracy': (metrics.macro_accuracy, IA()),\n",
    "    'micro_accuracy': (metrics.micro_accuracy, IA()),\n",
    "    'n_predicted_changes': (metrics.n_predicted_changes, IA()),\n",
    "    'any_predicted_changes': (metrics.any_predicted_changes, IA()),\n",
    "    'macro_accuracy_one_sub': (metrics.macro_accuracy_one_sub, IA()),\n",
    "    'micro_accuracy_one_sub': (metrics.micro_accuracy_one_sub, IA()),\n",
    "    'train_loss': (lambda **kwargs: kwargs['l'], IA()),\n",
    "    'accuracy_predicted_substation':\n",
    "        (metrics.accuracy_predicted_substation, IA())\n",
    "}\n",
    "val_metrics_dict = dict([('val_' + k, v) for k, v in metrics_dict.items()])\n",
    "val_metrics_dict['val_macro_accuracy_valid'] = (metrics.macro_accuracy_valid, IA())\n",
    "val_metrics_dict['val_micro_accuracy_valid'] = (metrics.micro_accuracy_valid, IA())\n",
    "IAM = metrics.IncrementalAverageMetrics\n",
    "eval_metrics = IAM(val_metrics_dict)\n",
    "\n",
    "# Action space cache\n",
    "as_cache = ActSpaceCache(line_outages_considered=train_config['settings']['line_outages_considered'])\n",
    "\n",
    "for i in tqdm.tqdm(model_numbers):\n",
    "    \n",
    "    # Model\n",
    "    model = \n",
    "\n",
    "    model_path = \n",
    "    state_dict = torch.load(model_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    # Dataloader\n",
    "    dataloader = DataLoader(seen_processed_data_path + '/test', seen_matrix_cache_path, feature_statistics_path, 'cpu',  model_type, network_type)\n",
    "\n",
    "    # Evaluate\n",
    "    eval_metrics.reset()\n",
    "    figures = evaluate_dataset(model, dataloader, as_cache, eval_metrics)\n",
    "\n",
    "    results[i] = {\n",
    "        'val_macro_accuracy_valid':  eval_metrics.metrics_dict['val_macro_accuracy_valid'][1].get(),\n",
    "        'loss':  eval_metrics.metrics_dict['val_train_loss'][1].get()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec4e80073b1c97f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_accuracy = np.mean([v['val_macro_accuracy_valid'] for v in results.values()])\n",
    "std_accuracy = np.std([v['val_macro_accuracy_valid'] for v in results.values()])\n",
    "print(mean_accuracy)\n",
    "print(std_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6c6fb-d45d-4a48-98f0-bc1115612bb7",
   "metadata": {},
   "source": [
    "## Unseen Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea645dbf002df690",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "model_numbers = np.arange(1,6)\n",
    "results = {}\n",
    "\n",
    "# Data\n",
    "unseen_processed_data_path = 'data/processed/greedy_unseen/'\n",
    "unseen_matrix_cache_path = unseen_processed_data_path + 'auxiliary_data_objects/con_matrix_cache.json'\n",
    "\n",
    "feature_statistics_path = seen_processed_data_path + 'auxiliary_data_objects/feature_stats.json'\n",
    "model_type = config['training']['hyperparams']['model_type']\n",
    "network_type = train_config['GCN']['hyperparams']['network_type']\n",
    "\n",
    "# Metrics\n",
    "# Initialize metrics objects\n",
    "IA = metrics.IncrementalAverage\n",
    "metrics_dict = {\n",
    "    'macro_accuracy': (metrics.macro_accuracy, IA()),\n",
    "    'micro_accuracy': (metrics.micro_accuracy, IA()),\n",
    "    'n_predicted_changes': (metrics.n_predicted_changes, IA()),\n",
    "    'any_predicted_changes': (metrics.any_predicted_changes, IA()),\n",
    "    'macro_accuracy_one_sub': (metrics.macro_accuracy_one_sub, IA()),\n",
    "    'micro_accuracy_one_sub': (metrics.micro_accuracy_one_sub, IA()),\n",
    "    'train_loss': (lambda **kwargs: kwargs['l'], IA()),\n",
    "    'accuracy_predicted_substation':\n",
    "        (metrics.accuracy_predicted_substation, IA())\n",
    "}\n",
    "val_metrics_dict = dict([('val_' + k, v) for k, v in metrics_dict.items()])\n",
    "val_metrics_dict['val_macro_accuracy_valid'] = (metrics.macro_accuracy_valid, IA())\n",
    "val_metrics_dict['val_micro_accuracy_valid'] = (metrics.micro_accuracy_valid, IA())\n",
    "IAM = metrics.IncrementalAverageMetrics\n",
    "eval_metrics = IAM(val_metrics_dict)\n",
    "\n",
    "# Action space cache\n",
    "as_cache = ActSpaceCache(line_outages_considered=train_config['settings']['line_outages_considered'])\n",
    "\n",
    "for i in tqdm.tqdm(model_numbers):\n",
    "    \n",
    "  # Model\n",
    "    model = GCN(train_config['hyperparams']['LReLu_neg_slope'],\n",
    "                train_config['hyperparams']['weight_init_std'],\n",
    "                train_config['GCN']['constants']['N_f_gen'],\n",
    "                train_config['GCN']['constants']['N_f_load'],\n",
    "                train_config['GCN']['constants']['N_f_endpoint'],\n",
    "                train_config['GCN']['hyperparams']['N_GCN_layers'],\n",
    "                train_config['hyperparams']['N_node_hidden'],\n",
    "                train_config['GCN']['hyperparams']['aggr'],\n",
    "                train_config['GCN']['hyperparams']['network_type'],\n",
    "                train_config['GCN']['hyperparams']['layer_type'],\n",
    "                train_config['GCN']['hyperparams']['GINConv_nn_depth'])\n",
    "\n",
    "    model_path = f'models/Hetero_unseen_{i}'\n",
    "    state_dict = torch.load(model_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "    # Dataloader\n",
    "    dataloader = DataLoader(unseen_processed_data_path + '/test', unseen_matrix_cache_path, feature_statistics_path, 'cpu',  model_type, network_type)\n",
    "\n",
    "    # Evaluate\n",
    "    eval_metrics.reset()\n",
    "    figures = evaluate_dataset(model, dataloader, as_cache, eval_metrics)\n",
    "\n",
    "    results[i] = {\n",
    "        'val_macro_accuracy_valid':  eval_metrics.metrics_dict['val_macro_accuracy_valid'][1].get(),\n",
    "        'loss':  eval_metrics.metrics_dict['val_train_loss'][1].get()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954c027157627c3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_accuracy = np.mean([v['val_macro_accuracy_valid'] for v in results.values()])\n",
    "std_accuracy = np.std([v['val_macro_accuracy_valid'] for v in results.values()])\n",
    "print(mean_accuracy)\n",
    "print(std_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357b9417b13e3966",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7a6ef0199a4f1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "seen_fcnn_accs = [0.7748490060397584, 0.7578896844126235, 0.7677292908283668, 0.7593296268149274, 0.7609695612175513]\n",
    "#unseen_fcnn_accs = [0.3449386985224772, 0.3489468720528136, 0.34855391386356493,0.3362150267211569, 0.35853505187048096]\n",
    "seen_homo_accs = [0.7254509819607216, 0.7299708011679533, 0.7242510299588016, 0.7251709931602736,0.7394504219831207]\n",
    "seen_hetero_accs = [0.7959681612735491, 0.7900483980640775, 0.7868085276588936, 0.7786488540458382, 0.7777688892444302]\n",
    "\n",
    "plt.violinplot([seen_fcnn_accs, seen_homo_accs, seen_hetero_accs],\n",
    "              showmeans=True)\n",
    "plt.gca().set_xticks([1, 2, 3])\n",
    "plt.gca().set_xticklabels(['FCNN', 'Homogeneous', 'Heterogeneous'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracies on the Test Set of Seen Networks')\n",
    "           #labels=≈)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f143be81de562f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unseen_fcnn_accs = [0.3449386985224772, 0.3489468720528136, 0.34855391386356493, 0.3362150267211569, 0.35853505187048096]\n",
    "unseen_homo_accs = [0.6087708267840302, 0.6119930839358693, 0.5985539138635649, 0.6211097139264382, 0.6128575919522162]\n",
    "unseen_hetero_accs = [0.655297076391072, 0.6583621502672116, 0.657340458975165, 0.6452373467463062, 0.6411505815781201]\n",
    "exposed_hetero_accs = [0.8025778057214712, 0.8088651367494498, 0.8142879597610814, 0.8068217541653568, 0.803520905375668]\n",
    "\n",
    "plt.violinplot([unseen_fcnn_accs, unseen_homo_accs, unseen_hetero_accs, exposed_hetero_accs],\n",
    "              showmeans=True)\n",
    "plt.gca().set_xticks([1, 2, 3, 4])\n",
    "plt.gca().set_xticklabels(['FCNN', 'Homogeneous', 'Heterogeneous', 'Exposed \\n Heterogeneous'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracies on the Test Set of Unseen Networks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c095fcea21a76",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84822fba-877c-4522-bfd0-fd94fc2cb92e",
   "metadata": {},
   "source": [
    "## Inspecting plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93abe33e076d60a6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_data_path = config['paths']['data']['processed']\n",
    "matrix_cache_path = processed_data_path + 'auxiliary_data_objects/con_matrix_cache.json'\n",
    "\n",
    "feature_statistics_path = processed_data_path + 'auxiliary_data_objects/feature_stats.json'\n",
    "model_type = config['training']['hyperparams']['model_type']\n",
    "network_type = train_config['GCN']['hyperparams']['network_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ff333f01c0272",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = FCNN(train_config['hyperparams']['LReLu_neg_slope'],\n",
    "                 train_config['hyperparams']['weight_init_std'],\n",
    "                 train_config['FCNN']['constants']['size_in'],\n",
    "                 train_config['FCNN']['constants']['size_out'],\n",
    "                 train_config['FCNN']['hyperparams']['N_layers'],\n",
    "                 train_config['hyperparams']['N_node_hidden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e2aa6865efea4f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path = config['paths']['model']\n",
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "dataloader = DataLoader(processed_data_path + '/val', matrix_cache_path, feature_statistics_path, 'cpu',  model_type, network_type)\n",
    "\n",
    "# Metrics\n",
    "# Initialize metrics objects\n",
    "IA = metrics.IncrementalAverage\n",
    "metrics_dict = {\n",
    "    'macro_accuracy': (metrics.macro_accuracy, IA()),\n",
    "    'micro_accuracy': (metrics.micro_accuracy, IA()),\n",
    "    'n_predicted_changes': (metrics.n_predicted_changes, IA()),\n",
    "    'any_predicted_changes': (metrics.any_predicted_changes, IA()),\n",
    "    'macro_accuracy_one_sub': (metrics.macro_accuracy_one_sub, IA()),\n",
    "    'micro_accuracy_one_sub': (metrics.micro_accuracy_one_sub, IA()),\n",
    "    'train_loss': (lambda **kwargs: kwargs['l'], IA()),\n",
    "    'accuracy_predicted_substation':\n",
    "        (metrics.accuracy_predicted_substation, IA())\n",
    "}\n",
    "val_metrics_dict = dict([('val_' + k, v) for k, v in metrics_dict.items()])\n",
    "val_metrics_dict['val_macro_accuracy_valid'] = (metrics.macro_accuracy_valid, IA())\n",
    "val_metrics_dict['val_micro_accuracy_valid'] = (metrics.micro_accuracy_valid, IA())\n",
    "IAM = metrics.IncrementalAverageMetrics\n",
    "eval_metrics = IAM(val_metrics_dict)\n",
    "\n",
    "# Action space cache\n",
    "as_cache = ActSpaceCache(line_outages_considered=train_config['settings']['line_outages_considered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a7bc274680196",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapoints = []\n",
    "\n",
    "line_disabled = 6\n",
    "# Loading datapoints\n",
    "for dp in tqdm.tqdm(dataloader):\n",
    "    if dp['line_disabled'] != line_disabled:\n",
    "        continue\n",
    "        \n",
    "    l, Y, P, nearest_valid_P, Y_sub_idx, Y_sub_mask, P_subchanged_idx, \\\n",
    "                nearest_valid_actions = process_datapoint(dp, model, as_cache, eval_metrics)\n",
    "\n",
    "    set_action_Y = [t if (c<0.5) else 1+((t-1+c)%2) for t,c in zip(dp['full_topo_vect'].numpy(),dp['full_change_topo_vect'].tolist()) if t!=-1]\n",
    "    set_action_P = [t if (c<0.5) else 1+((t-1+c)%2) for t,c in zip(dp['full_topo_vect'].numpy(),nearest_valid_P.detach().numpy()) if t!=-1]\n",
    "    Y_string = ''.join([str(int(i)-1) for i in set_action_Y])\n",
    "    P_string = ''.join([str(int(i)-1) for i in set_action_P])\n",
    "    \n",
    "    datapoints.append([dp['features'].numpy(), Y_string, P_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd681b0d092f9087",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "confusions = Counter()\n",
    "\n",
    "# Counting the confusions\n",
    "for dp in datapoints:\n",
    "    Y = dp[1]\n",
    "    P = dp[2]\n",
    "\n",
    "    if Y==P:\n",
    "        continue\n",
    "        \n",
    "    if int(Y, 2) < int(P, 2):\n",
    "        confusions[(Y, P)] += 1\n",
    "    else:\n",
    "        confusions[(P, Y)] += 1\n",
    "\n",
    "most_common_confusions = confusions.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351c564995b6b75",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1debc59b5b5791",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Performing the PCA\n",
    "X = np.array([dp[0] for dp in datapoints])\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41d8373a5892a22",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_rank = 3\n",
    "confused_class1, confused_class2 = most_common_confusions[confusion_rank][0]\n",
    "color_map = {confused_class1: 'g', confused_class2: 'b'}\n",
    "\n",
    "datapoints_either_class = [dp for dp in datapoints if dp[1] in (confused_class1, confused_class2)]\n",
    "either_class_color = [color_map[dp[1]] for dp in datapoints_either_class]\n",
    "either_class_X = np.array([dp[0] for dp in datapoints_either_class])\n",
    "\n",
    "confused = [dp for dp in datapoints_either_class if (dp[1] != dp[2] and dp[2] in (confused_class1, confused_class2))]\n",
    "confused_X = np.array([dp[0] for dp in confused])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991fac9498f8a3a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "plt.scatter(*pca.transform(either_class_X).T, color=either_class_color, marker='x')\n",
    "plt.scatter(*pca.transform(confused_X).T, color='r', alpha=0.3)\n",
    "plt.xlabel('Principal Component 1',fontsize=12)\n",
    "plt.ylabel('Principal Component 2',fontsize=12)\n",
    "custom = [Line2D([], [], marker='x', color='blue', linestyle='None'),\n",
    "          Line2D([], [], marker='x', color='green', linestyle='None'),\n",
    "          Line2D([], [], marker='o', color='red', linestyle='None', alpha=1.0)]\n",
    "\n",
    "plt.legend(handles = custom, labels=['Class 1', 'Class 2', 'Confusion'], loc= \"upper left\")\n",
    "#plt.savefig('class_overlap_l2', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea9b40252222fce",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Inspecting nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a83944f890cbef",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_selection = 2500\n",
    "\n",
    "selected_datapoints = datapoints[:N_selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c0a62c98272870",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances = np.zeros((N_selection, N_selection))\n",
    "\n",
    "for i in tqdm.tqdm(range(N_selection)):\n",
    "    for j in range(N_selection):\n",
    "\n",
    "        # Skipping symmetric\n",
    "        if i > j:\n",
    "            continue\n",
    "\n",
    "        dist = np.linalg.norm(selected_datapoints[i][0]-selected_datapoints[j][0])\n",
    "\n",
    "        distances[i,j] = dist\n",
    "        distances[j,i] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5511c394318351",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.fill_diagonal(distances, np.inf)\n",
    "neighbours_by_nearness = np.argsort(distances, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a26d3fd3ffdd338",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighbours_by_nearness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e920c58f0272f28f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(selected_datapoints), np.mean([dp[1]==dp[2] for dp in selected_datapoints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b27ad161e95784",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapoints_nearest_neighbour_same_class = [dp[1]==dp[2] for i, dp in enumerate(selected_datapoints) \n",
    "                                           if dp[1]!=selected_datapoints[neighbours_by_nearness[0,i]][1]]\n",
    "len(datapoints_nearest_neighbour_same_class), 1-np.mean(datapoints_nearest_neighbour_same_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9a03bd3faa7270",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapoints_2_nearest_neighbour_same_class = [dp[1]==dp[2] for i, dp in enumerate(selected_datapoints) \n",
    "                                             if (dp[1] == selected_datapoints[neighbours_by_nearness[0,i]][1] and \n",
    "                                                 dp[1] == selected_datapoints[neighbours_by_nearness[1,i]][1] and \n",
    "                                                 dp[1] == selected_datapoints[neighbours_by_nearness[2,i]][1])]\n",
    "len(datapoints_2_nearest_neighbour_same_class), np.mean(datapoints_2_nearest_neighbour_same_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5dcb72-fda4-467e-bbe2-c9aff6706659",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Plotting durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c5084-7d45-4a1f-861a-936ae02a526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_unplanned = [81.79, 92.76, 86.33, 89.62, 93.76, 95.17]\n",
    "accuracies_full = [99.73, 100.0, 96.27, 98.95, 99.85, 99.97]\n",
    "durations = [6.77E5, 4.70E6, 5.74E2, 1.14E4, 3.29E4, 9.26E4]\n",
    "labels = ['Greedy', 'N-1', 'Naive', 'Verify', 'Greedy Hybrid', 'N-1 Hybrid']\n",
    "color = 2*['r'] + ['g'] + 3*['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170f6f6-5cfb-4d6e-9f17-209604b5ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies=accuracies_full\n",
    "\n",
    "plt.scatter(durations, accuracies, c=color)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.ylabel('Mean days completed (%)', fontsize=12)\n",
    "plt.xlabel('Mean log duration (μs)', fontsize=12)\n",
    "\n",
    "\n",
    "for i, txt in enumerate(labels):\n",
    "    x_offset = 0.1\n",
    "    y_offset = 0.1\n",
    "    if i == 1:\n",
    "        x_offset = -1000000\n",
    "        y_offset = -0.25\n",
    "    if i == 4:\n",
    "        x_offset = 0\n",
    "        y_offset = -0.25\n",
    "    if i == 5:\n",
    "        x_offset = 15000\n",
    "        y_offset = -0\n",
    "    # if i==5:\n",
    "    #     x_offset=2E4\n",
    "    # elif i==1:\n",
    "    #     x_offset=-1E6\n",
    "    plt.gca().annotate(txt, (x_offset+durations[i], y_offset+accuracies[i]), fontsize=12)\n",
    "plt.savefig('tradeoff_full', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95326ef-9f83-42a4-9219-e32d95acdfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN_MSc_kernel",
   "language": "python",
   "name": "gnn_msc_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
